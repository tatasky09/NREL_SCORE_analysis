---
title: "01_combined_explorative_analysis"
author: "SimanNing"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This documents combined all my initial analysis with the data. The process will take in a few steps:
- Data cleaning
- Descriptive tables
- Cramer's V (check correlation between different categorical variables)
- Sankey Diagram
- Simple Regression


### data cleaning
```{r Data Cleaning}
library(readxl)  # for reading Excel files
library(sf)      # for spatial data manipulation
library(ggplot2) # for plotting
library(tigris)  # for census boundary data
library(tidycensus)
library(dplyr)

# 1. Read Excel file
# Replace 'your_excel_file.xlsx' with the path to your Excel file, and 'Sheet1' with your sheet name
## SKIP 1 and 2 rows and use the third row as column names- don't capitalize

data <- read_excel("D:/01PHD/000NREL_SCORE/04analysis/data/Data_Analysis_1021.xlsx",sheet=1,skip = 2, col_names = TRUE)
# Remove the second row from the data
colnames(data) <- tolower(colnames(data))
df1<- data ##removing 1 will result in not knowing which Q will respond to 

##read the csv and header is the first row
vul_index <- read.csv("D:/01PHD/000NREL_SCORE/04analysis/data/Vulnerability_Indices.csv", header = TRUE)
colnames(vul_index) <- tolower(colnames(vul_index))
vul_index$responseid %in% data$response_id
##check if vul_index$response_id is all in data$response_id
vul_index <- vul_index[2:118,2:18]
vul_index_prefixed <- vul_index %>% rename_with(~ paste0("idx_", .))

# Set the second row as column names

###load the cleaned address and coordinates
geocoded_data3 <- read.csv('D:/01PHD/000NREL_SCORE/04analysis/data/clean_address4.csv')[,c(2,5,6)]

geocoded_data3$latitude <- as.numeric(geocoded_data3$latitude)
geocoded_data3$longitude <- as.numeric(geocoded_data3$longitude)
df1$longitude <- NULL
df1$latitude <- NULL
df2 <- left_join(df1, geocoded_data3)
##join the table, and add "indx_" to the front of column names in vul_index to avoid confusion
df2 <- left_join(df2, vul_index_prefixed,by = c("response_id" = "idx_responseid") )
# Assume the data has columns 'lat' and 'lon' for latitude and longitude
# Convert the lat and lon into spatial points
df_sf <- st_as_sf(df2, coords = c("longitude", "latitude"), crs = 4326)  #
df2 <- df2 %>% mutate(across(everything(), ~ gsub("â€™", "'", .)))
##############getting census data
colnames(df2)
save(df2,file ="D:/01PHD/000NREL_SCORE/04analysis/data/useful_set_11_18.RData")



######################do a round of new rdata and new vulnerability Index
vul_index <- read.csv("D:/01PHD/000NREL_SCORE/04analysis/data/Vulerability_Index_1129.csv", header = TRUE)
colnames(vul_index) <- tolower(colnames(vul_index))
vul_index$response_id %in% data$response_id
##check if vul_index$response_id is all in data$response_id

###load the cleaned address and coordinates
geocoded_data3 <- read.csv('D:/01PHD/000NREL_SCORE/04analysis/data/clean_address4.csv')[,c(2,5,6)]

geocoded_data3$latitude <- as.numeric(geocoded_data3$latitude)
geocoded_data3$longitude <- as.numeric(geocoded_data3$longitude)
df1$longitude <- NULL
df1$latitude <- NULL
df2 <- left_join(df1, geocoded_data3)
##join the table, and add "indx_" to the front of column names in vul_index to avoid confusion
df2 <- left_join(df2, vul_index,by = c("response_id" = "response_id") )
# Assume the data has columns 'lat' and 'lon' for latitude and longitude
# Convert the lat and lon into spatial points
df_sf <- st_as_sf(df2, coords = c("longitude", "latitude"), crs = 4326)  #
df2 <- df2 %>% mutate(across(everything(), ~ gsub("â€™", "'", .)))
##############getting census data
colnames(df2)
save(df2,file ="D:/01PHD/000NREL_SCORE/04analysis/data/useful_set_11_29.RData")

```

##data cleaning
```{r pressure, echo=FALSE}
# Install and load the tidyr package
data <- df2[,-c(1:8,10:14,16)]

# Assuming your data is in a data frame called 'data'
columns_with_less_than_20_na <- names(data)[colSums(is.na(data)) <= 20]
length(columns_with_less_than_20_na)
# Print the column names
print(columns_with_less_than_20_na)


drop_cols2 <- c("start_date" , "address" ,  "user_language"   , "consent_to_participate","zip_code","city","state",  "future_activity_contact" ,  "survey_source_selected" ,   "select",   "longitude" ,"latitude" ,"Index" ,"ResponseId" ,"neighborhood","response_id"    )

data <- data[,columns_with_less_than_20_na]
data <- data[,! colnames(data) %in% drop_cols2 ]
# Assuming your data is in a data frame called 'data'

unwanted_string <- c("\\$\\{q://QID3/ChoiceGroup/SelectedChoices\\}","â€™")
data<- as.data.frame(
  lapply(data, function(column) gsub(unwanted_string, "", column)),
  stringsAsFactors = FALSE
)

colnames(data)
```
### make descriptive tables to the variables
```{r descriptive table}

library(table1)
# paste(names(data), collapse = " + ")

#### demographic, household information
table1(~ age  + gender + work_location + home_ownership + housing_type + household_size + household_race_selected + hispanic_latino_count + hh_income + education_level + condition_worsened_by_outage + electric_device_dependent + prescription_med + primary_transport_mode_selected + vehicle_count + energy_sources_selected + backup_energy_system + seattle_city_light_bill + seattle_city_light_discounts + greenup_participant + shutoff_notice + bill_affordability | neighborhood, data=data)

###blueksy frequency table       
table1(~  location_use_frequency_pharmacy + location_use_frequency_grocery_store + location_use_frequency_convenience_store + location_use_frequency_food_bank + location_use_frequency_school + location_use_frequency_gas_station + location_use_frequency_community_center + location_use_frequency_worship + location_use_frequency_bank + location_use_frequency_doctor + location_use_frequency_dialysis + location_use_frequency_hardware_store + location_use_frequency_trusted_hh | neighborhood, data=data)

####black sky frequency         
table1(~     shelf_stable_food_days + bottled_water_days + emergency_savings + power_outage_experience +  affordability_worry  +  relocation_option + community_outage_concern_selected + outage_need_adaptation_food + outage_need_adaptation_healthcare + outage_need_adaptation_food_cooling + outage_need_adaptation_cooking + outage_need_adaptation_washing + outage_need_adaptation_comfort + outage_need_adaptation_lighting + outage_need_adaptation_info + outage_need_adaptation_comm + primary_reason_facility_selected | neighborhood, data=data) #+ neighborhood 
###outage_concern_description + health_impact_explanation +disrupted_health_impact_selected +  + activity_disruption_adaptation_selected + same_facility_during_outage + future_activity_contact + survey_source_selected + activity_disruption_health_impact_selected 

##table all the variables with prefix idx_ in table 1 to see the distribution
table1(~ idx_no_vehicle + idx_lowet_than_median_income + idx_no_back_up_energy + idx_less_than_highschool_education + idx_children_under_18 + idx_children_under_5 + idx_single_parent_house + idx_members_over_65 + idx_language_other_than_eng + idx_renter + idx_non_white + idx_hispanic_latino + idx_condition_worsened_by_blackout + idx_medical_device + idx_prescription_medicine + idx_total.vi |neighborhood, data=df2)

##find all columns that with idx in the name of data
# idx_columns <- grep("idx_", colnames(data), value = TRUE)
# paste0(idx_columns, collapse = " + ")
```
Some variables are multi choices: 
activity_disruption_adaptation_selected
activity_disruption_health_impact_selected


########basic descriptive
```{r summary Graphic}
summary(data) ## not work great for categories

```


###This section makes the Cramer's V

test association between categorical variables
```{r Cramers V, warning=FALSE}

# Function to calculate Cramér's V
cramers_v <- function(x, y) {
  chi2 <- chisq.test(table(x, y))
  n <- sum(chi2$observed)
  min_dim <- min(dim(chi2$observed)) - 1
  sqrt(chi2$statistic / (n * min_dim))
}
data1 <- data %>%
  mutate(across(where(~ !is.numeric(.)), as.factor))
# Get all combinations of pairs of categorical variables

library(dplyr)
library(purrr)

data2 <- data1 %>%
  mutate(across(where(is.factor), ~ {
    # Check if factor has more than 20 levels
    if (nlevels(.x) > 20) {
      # Try converting to numeric
      numeric_values <- as.numeric(as.character(.x))
      
      # If successful, return numeric; if not, return character
      if (all(!is.na(numeric_values))) {
        return(numeric_values)
      } else {
        return(as.character(.x))
      }
    } else {
      # Return the original factor if levels are <= 20
      return(.x)
    }
  }))


categorical_vars <- names(data2)[sapply(data2, is.factor)]
combinations <- combn(categorical_vars, 2, simplify = FALSE)

# Calculate Cramér's V for each pair
cramers_v_results <- sapply(combinations, function(pair) {
  cramers_v(data2[[pair[1]]], data2[[pair[2]]])
})

# Create a matrix to show results
cramers_v_matrix <- matrix(NA, nrow = length(categorical_vars), ncol = length(categorical_vars),
                           dimnames = list(categorical_vars, categorical_vars))

for (i in seq_along(combinations)) {
  pair <- combinations[[i]]
  cramers_v_matrix[pair[1], pair[2]] <- cramers_v_results[i]
  cramers_v_matrix[pair[2], pair[1]] <- cramers_v_results[i] # Symmetric matrix
}

# Load necessary packages
library(ggplot2)
library(reshape2)

# Assuming `cramers_v_matrix` is your matrix of Cramér's V values
# Melt the matrix to long format
cramers_v_melt <- melt(cramers_v_matrix, na.rm = TRUE)
##round all the values to 0.01
cramers_v_melt$value <- round(cramers_v_melt$value,2)

write.csv(cramers_v_melt,"D:/01PHD/000NREL_SCORE/04analysis/data/output/cramers_v_melt_11_18.csv")
# View the reshaped data
head(cramers_v_melt)
# Create heatmap with ggplot2
cramers_v_heatmap<- ggplot(cramers_v_melt, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient(low = "blue", high = "red", name = "Cramér's V") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 60, hjust = 1)) +
  labs(x = "Variable 1", y = "Variable 2", title = "Cramér's V Heatmap") +
  geom_text(aes(label = round(value, 2)), size = 2, color = "black")
ggsave(filename = "D:/01PHD/000NREL_SCORE/04analysis/data/output/cramers_v_heatmap.jpg", plot = cramers_v_heatmap, width = 16, height = 12, dpi = 300)
cramers_v_heatmap


```
There are two types of analysis we can explore with this. We can investigate correlations (or possibly a regression) to see how the vulnerability score is associated with answers to other questions. Our priority should be seeing how the vulnerability score is associated (or not) with the frequency of certain types of POIs and particular POIs for each type. We might expect that more vulnerable households might, for example, live more paycheck to paycheck, and perhaps frequent grocery stores more often. I think we could see if more vulnerable households also seem less prepared for an outage, by looking for associations between the preparedness questions and vulnerability score. 

Once we explore that, we can think about particular types of vulnerabilities that we might want to look deeper. I think the following vulnerabilities would warrant a deeper investigation:
-homes without access to a car
-low-income households
-household with a disability
-households with kids
-households with seniors
-households that rent
For these, we would only look at the sub-sample of households that meet these criteria and see if their answers are significantly distinct from others in the sample. 

```{r test association}
library(dplyr) 
library(purrr) 
library(tidyverse)

### test assocaition among the vul_index



# Function to calculate association between numeric and numeric variables
association_numeric <- function(x, y) {
  cor(x, y, use = "complete.obs")
}

# Function to calculate association between categorical and categorical variables
association_categorical <- function(x, y) {
  chisq.test(table(x, y))$statistic
}

# Function to calculate association between numeric and categorical variables
association_mixed <- function(x, y) {
  aov(x ~ as.factor(y))$`Pr(>F)`[1]
}

# Wrapper function to handle different types
calculate_association <- function(var1, var2) {
  if (is.numeric(var1) && is.numeric(var2)) {
    association_numeric(var1, var2)
  } else if (is.factor(var1) && is.factor(var2)) {
    association_categorical(var1, var2)
  } else if ((is.numeric(var1) && is.factor(var2)) || (is.factor(var1) && is.numeric(var2))) {
    association_mixed(var1, var2)
  } else {
    NA
  }
}


# Get all pairs of columns
pairs <- combn(names(data), 2, simplify = FALSE)

# Calculate associations for each pair
associations <- map_dfr(pairs, function(pair) {
  data.frame(
    Var1 = pair[1],
    Var2 = pair[2],
    Association = calculate_association(data[[pair[1]]], data[[pair[2]]])
  )
})

# Print the associations table
print(associations)


```


######deal with multiple-choice data. Try to use function to create longer form, and then do a frequency table for each variables we are interested. Good to test whether certain frequency appear more across demogrphic/age/household (this one is best not multi-choice)

{TODO}
TO-DO: move from the choice 2 file to here--> everything changed
```{r combined data} 

load("D:/01PHD/000NREL_SCORE/04analysis/data/useful_set.RData")
load("D:/01PHD/000NREL_SCORE/04analysis/data/combined_data_choice_1021.Rdata")
library(tidyverse)
library(tidyverse)
library(stringr)

# Define the function
word_frequency_by_nb <- function(data, text_columns, nb_column) {
  # Loop through each text column
  word_counts <- map_dfr(text_columns, function(column) {
    data %>%
      # Clean the text: remove unwanted patterns, make lowercase, and remove "'s"
      mutate(cleaned_text = .data[[column]]) %>%
      # mutate(cleaned_text = str_replace_all(cleaned_text, "(?i)Other \\(Please explain\\):;|\\(Please explain\\):;", "")) %>%
      mutate(cleaned_text = tolower(cleaned_text)) %>%
      mutate(cleaned_text = str_replace_all(cleaned_text, "'s", "")) %>%
      # Split into individual words based on ',' or ';'
      mutate(words = str_split(cleaned_text, ",(?![^()]*\\))|;")) %>% ##,
      # Unnest the list of words into rows
      unnest(words) %>%
      # Trim any whitespace around words
      mutate(words = str_trim(words)) %>%
      # Group by NB column and word
      group_by(!!sym(nb_column), column_name = column, words) %>%
      # Count occurrences
      count(name = "frequency")
  })
  
  # Pivot the table to have NB as columns, words as rows, and frequencies as values
  word_counts_pivot <- word_counts %>%
    pivot_wider(names_from = !!sym(nb_column), 
                values_from = frequency, 
                values_fill = list(frequency = 0)) %>%
    arrange(column_name, words)
  word_counts_pivot$total <- rowSums(word_counts_pivot[,3:8])
  return(word_counts_pivot)
}
# Example usage
# Assuming 'data' is your dataframe, 'NB' is the grouping column, and c("names_column1", "names_column2") are the text columns
word_freq_result <- word_frequency_by_nb(data_combined , c( "typical_dialysis_center_selected","combined_grocery_store", "combined_convenience_store", "combined_food_bank"  , "combined_school"    ,"combined_community_center" ,  "combined_worship_place" , "combined_bank" , "combined_doctor" , "combined_hardware_store","combined_pharmacy","combined_gas_station" ), "neighborhood")
print(word_freq_result)

write.csv(word_freq_result,'D:/01PHD/000NREL_SCORE/04analysis/data/output/word_freq_result.csv')
word_freq_result_age <- word_frequency_by_nb(data_combined , c( "typical_dialysis_center_selected","combined_grocery_store", "combined_convenience_store", "combined_food_bank"  , "combined_school"    ,"combined_community_center" ,  "combined_worship_place" , "combined_bank" , "combined_doctor" , "combined_hardware_store","combined_pharmacy" ), "age_group")
print(word_freq_result_age)

##disability-- medical equipment
```
```{r simple frequency}

simple_frequency <- function(data, text_columns) {
  word_counts <- map_dfr(text_columns, function(column) {
    data %>%
      # Clean the text: make lowercase and remove "'s"
      mutate(cleaned_text = tolower(.data[[column]])) %>%
      mutate(cleaned_text = str_replace_all(cleaned_text, "'s", "")) %>%
      # Split into individual words based on ',' or ';'
      mutate(words = str_split(cleaned_text, ",(?![^()]*\\))|;")) %>% 
      # Unnest the list of words into rows
      unnest(words) %>%
      # Trim any whitespace around words
      mutate(words = str_trim(words)) %>%
      # Remove empty strings
      filter(words != "") %>%
      # Group by the original column name and word
      group_by(column_name = column, words) %>%
      # Count occurrences
      tally(name = "frequency") %>%
      ungroup()
  })
  return(word_counts)
}

word_freq_result_blacksky <- simple_frequency(data_combined , c( "combined_food_access_location"             
, "combined_healthcare_access_location"   ,     "combined_food_cooling_access_location"     
, "combined_cooking_access_location"        ,   "combined_med_cooling_access_location"      
, "combined_healthcare_device_access_location", "combined_washing_access_location_location" 
, "combined_comfort_access_location"           ,"combined_lighting_access_location"         
, "combined_info_access_location"             , "combined_comm_access_location"             
, "combined_other_task_location" ))

#pivot to a wider form using the word frequency
word_freq_result_blacksky_wider <- word_freq_result_blacksky %>%
  pivot_wider(names_from = column_name, values_from = frequency, values_fill = list(frequency = 0)) %>%
  arrange(words)

write.csv(word_freq_result_blacksky,'D:/01PHD/000NREL_SCORE/04analysis/data/output/word_freq_result_blacksky.csv')
write.csv(word_freq_result_blacksky_wider,'D:/01PHD/000NREL_SCORE/04analysis/data/output/word_freq_result_blacksky_wider.csv')

```


```{r}
```
#### do a frequency test to many different types of demographic variable
```{r}
library(dplyr)
library(tidyr)

analyze_multi_choice <- function(data, multi_choice_column, group_var) {
  
  # Step 1: Detect if the grouping variable is categorical or numeric
  group_var_type <- if (is.numeric(data[[group_var]])) "numeric" else "categorical"
  
  # Step 2: Separate the multi-choice column into multiple rows
  data_long <- data %>%
    separate_rows(!!sym(multi_choice_column), sep = ";|,") %>%
    mutate(!!sym(multi_choice_column) := str_trim(!!sym(multi_choice_column)))  # Clean whitespace
  
  # Step 3: Group by the multi-choice column and the grouping variable
  freq_table <- data_long %>%
    group_by(!!sym(multi_choice_column), !!sym(group_var)) %>%
    summarise(count = n(), .groups = 'drop')  # Frequency count
  
  # Step 4: Perform statistical tests
  if (group_var_type == "categorical") {
    # Chi-Square Test for categorical group_var
    chisq_test_result <- data_long %>%
      group_by(!!sym(multi_choice_column)) %>%
      filter(sum(table(!!sym(group_var), !!sym(multi_choice_column)) > 0) > 1) %>%  # Ensure there are valid comparisons
      summarise(
        p_value = chisq.test(table(!!sym(group_var), !!sym(multi_choice_column)))$p.value
      )
    
    print("Chi-Square Test Results (P-values):")
    print(chisq_test_result)
    
  } else if (group_var_type == "numeric") {
    # ANOVA Test for numeric group_var
    anova_test_result <- data_long %>%
      group_by(!!sym(multi_choice_column)) %>%
     filter(n_distinct(!!sym(multi_choice_column)) > 1,  # Ensure there are at least 2 distinct levels in multi_choice_column
             n_distinct(!!sym(group_var)) > 1) %>%  # Ensure at least 2 distinct levels in group_var
      summarise(
        p_value = if (n() > 1) {  # Only run ANOVA if there are enough data points
          summary(aov(as.numeric(!!sym(group_var)) ~ !!sym(multi_choice_column)))$"Pr(>F)"[1]
        } else {
          print("not enough data") # Return NA if there's not enough data
        }
      )
    
    print("ANOVA Test Results (P-values):")
    print(anova_test_result)
  }
  
  # Step 5: Return the frequency table and the test results
  return(freq_table)
}
multi_choice_frequency_grocery_income<- analyze_multi_choice(data_combined, "combined_grocery_store", "hh_income") 


multi_choice_frequency_grocery_age<- analyze_multi_choice(data_combined, "combined_grocery_store", "age_group") 
```

# Sankey Diagram

```{r sankey prep}
###this is using the combined_data 
cols_bluesky <-c(  "relocation_option","combined_relocation_location","location_use_frequency_pharmacy",
   "location_use_frequency_grocery_store","location_use_frequency_convenience_store","location_use_frequency_food_bank","location_use_frequency_school","location_use_frequency_gas_station","location_use_frequency_community_center","location_use_frequency_worship","location_use_frequency_bank","location_use_frequency_doctor","location_use_frequency_dialysis","location_use_frequency_hardware_store","location_use_frequency_trusted_hh")

cols_blue_black_food <-c("location_use_frequency_grocery_store","relocation_option","same_facility_during_outage","combined_primary_reason_facility","count_relocation_destination" )
cols_blue_black_pharmacy <-c("location_use_frequency_pharmacy","relocation_option","same_facility_during_outage","combined_primary_reason_facility" )
cols_blue_black_food_bank <-c("location_use_frequency_food_bank","relocation_option","same_facility_during_outage","combined_primary_reason_facility" )

cols_blue_black_bank <-c("location_use_frequency_bank","relocation_option","same_facility_during_outage","combined_primary_reason_facility" )

cols_blue_black_community_center <-c("location_use_frequency_community_center","relocation_option","same_facility_during_outage","combined_primary_reason_facility" )
#"combined_convenience_store","combined_food_bank","combined_grocery_store","combined_relocation_location"


cols_blue_black_food_typical <-c("location_use_frequency_grocery_store","typical_grocery_store_1")

```

```{r sankey diagram}
library(networkD3)
library(dplyr)

# Define the function
create_sankey <- function(data, cols) {
  # Select the specified columns
  df <- data[, colnames(data) %in% cols]
    # Replace NAs with 'NA'
  df[is.na(df)] <- "missing"
  df <- df %>%
  mutate(across(where(is.numeric), as.factor))

  # Get unique categories
  categories <- unique(unlist(df))
  nodes <- data.frame(name = categories)
  
  # Initialize an empty data frame for links
  links <- data.frame()
  
  # Populate the links
  for (i in 1:(ncol(df) - 1)) {
    source_column <- df[, i]
    target_column <- df[, i + 1]
    
    for (j in 1:nrow(df)) {
      source <- which(nodes$name == source_column[j])
      target <- which(nodes$name == target_column[j])
      
      # Check if source and target are found
      if(length(source) > 0 & length(target) > 0) {
        links <- rbind(links, data.frame(source = source - 1, target = target - 1, value = 1))
      }
    }
  }
  
  # Aggregate the values for each link
  links <- aggregate(value ~ source + target, data = links, FUN = sum)
  
  # Create the Sankey diagram
  sankeyNetwork(Links = links, Nodes = nodes, Source = "source", Target = "target", Value = "value", NodeID = "name", units = "people")
  
}
cols_bluesky
# Example usage
create_sankey(data_combined, cols_bluesky )
create_sankey(data_combined, cols_blue_black_food )
create_sankey(data_combined, cols_blue_black_pharmacy)
create_sankey(data_combined, cols_blue_black_food_bank)
create_sankey(data_combined, cols_blue_black_bank)
create_sankey(data_combined, cols_blue_black_community_center)


create_sankey(data_combined, c("household_race_selected",	"relocation_option"))	#0.410383
create_sankey(data_combined, c("hh_income",	"relocation_option"))
create_sankey(data_combined, c("education_level","relocation_option"))	#0.303596
create_sankey(data_combined, c("combined_primary_transport_mode",	"relocation_option"))
create_sankey(data_combined, c("combined_energy_sources",	"relocation_option"))
create_sankey(data_combined, c("location_use_frequency_community_center",	"relocation_option"))
create_sankey(data_combined, c("location_use_frequency_bank",	"relocation_option"))

####note that this don't work well with the multiple choice data --> if we really must use it, we might need to first separate the rows using the separate_row function, and then do a frequency
```


--------------
# Start from here is just for your info

######## deal with multiple-choice data. 
This one transform data into longer and wider form. The wider form may be too much if the levels of cateogories are too many.
```{r not too useful for now}
# Step 1: Split the reasons into separate rows
data_long <- data %>%
  separate_rows(health_impact_explanation, sep = ",") %>%         # Split by semicolon
  mutate(health_impact_explanation = str_trim(health_impact_explanation)) %>%        # Remove leading/trailing whitespace
  mutate(value = 1)                            # Create a binary column



# Step 2: Reshape to wide format
data_wide <- data_long %>%
  pivot_wider(names_from = health_impact_explanation,             # Create columns for each unique reason
              values_from = value,             # Fill these columns with 1
              values_fill = list(value = 0))   # Fill missing combinations with 0


```

```{r mapping}
###too much to cover, maybe later

```
If you are interested in how the data was combined, here is the data processing dump

```{r how to combine data messy}
data_combined <- data %>%
  unite(col = "combined_pharmacy", 
        c("typical_pharmacy_selected" ,"typical_pharmacy_other" , "typical_pharmacy_1", "typical_pharmacy_2", "typical_pharmacy_3", "typical_pharmacy_4", "typical_pharmacy_5", "typical_pharmacy_6",   "typical_pharmacy_7",   "typical_pharmacy_8" , "typical_pharmacy_9" , "typical_pharmacy_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining
  unite(col = "combined_grocery_store", 
        c("typical_grocery_store_selected", "typical_grocery_store_other" , "typical_grocery_store_1", "typical_grocery_store_2", "typical_grocery_store_3", "typical_grocery_store_4", "typical_grocery_store_5", "typical_grocery_store_6",   "typical_grocery_store_7",   "typical_grocery_store_8" , "typical_grocery_store_9" , "typical_grocery_store_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% # Removes NA values before combining
  unite(col = "combined_convenience_store", 
        c("typical_convenience_store_selected" ,"typical_convenience_store_other" , "typical_convenience_store_1", "typical_convenience_store_2", "typical_convenience_store_3", "typical_convenience_store_4", "typical_convenience_store_5", "typical_convenience_store_6",   "typical_convenience_store_7",   "typical_convenience_store_8" , "typical_convenience_store_9" , "typical_convenience_store_10" ), sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining
  unite(col = "combined_food_bank", 
        c("typical_food_bank_selected", "typical_food_bank_other" , "typical_food_bank_1", "typical_food_bank_2", "typical_food_bank_3", "typical_food_bank_4", "typical_food_bank_5", "typical_food_bank_6",   "typical_food_bank_7",   "typical_food_bank_8" , "typical_food_bank_9" , "typical_food_bank_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining  
  unite(col = "combined_school", 
        c("typical_school_selected" ,"typical_school_other" , "typical_school_1", "typical_school_2", "typical_school_3", "typical_school_4", "typical_school_5", "typical_school_6",   "typical_school_7",   "typical_school_8" , "typical_school_9" , "typical_school_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining
  unite(col = "combined_gas_station", 
        c("typical_gas_station_selected" ,"typical_gas_station_other" , "typical_gas_station_1", "typical_gas_station_2", "typical_gas_station_3", "typical_gas_station_4", "typical_gas_station_5", "typical_gas_station_6",   "typical_gas_station_7",   "typical_gas_station_8" , "typical_gas_station_9" , "typical_gas_station_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining  
  unite(col = "combined_community_center", 
        c("typical_community_center_selected" ,"typical_community_center_other" , "typical_community_center_1", "typical_community_center_2", "typical_community_center_3", "typical_community_center_4", "typical_community_center_5", "typical_community_center_6",   "typical_community_center_7",   "typical_community_center_8" , "typical_community_center_9" , "typical_community_center_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining  
  unite(col = "combined_worship_place", 
        c("typical_worship_place_selected" , "typical_worship_place_other" , "typical_worship_place_1", "typical_worship_place_2", "typical_worship_place_3", "typical_worship_place_4", "typical_worship_place_5", "typical_worship_place_6",   "typical_worship_place_7",   "typical_worship_place_8" , "typical_worship_place_9" , "typical_worship_place_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining  
  unite(col = "combined_bank", 
        c("typical_bank_selected" , "typical_bank_other" , "typical_bank_1", "typical_bank_2", "typical_bank_3", "typical_bank_4", "typical_bank_5", "typical_bank_6",   "typical_bank_7",   "typical_bank_8" , "typical_bank_9" , "typical_bank_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining  
  unite(col = "combined_doctor", 
        c("typical_doctor_selected" ,"typical_doctor_other" , "typical_doctor_1", "typical_doctor_2", "typical_doctor_3", "typical_doctor_4", "typical_doctor_5", "typical_doctor_6",   "typical_doctor_7",   "typical_doctor_8" , "typical_doctor_9" , "typical_doctor_10" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%# Removes NA values before combining
  unite(col = "combined_hardware_store", 
        c("typical_hardware_store_selected" ,"typical_hardware_store_other" , "typical_hardware_store_1", "typical_hardware_store_2", "typical_hardware_store_3", "typical_hardware_store_4", "typical_hardware_store_5", "typical_hardware_store_6",   "typical_hardware_store_7",   "typical_hardware_store_8" , "typical_hardware_store_9" , "typical_hardware_store_10" , "typical_hardware_store_11" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) 


data_combined <- data_combined %>%
  unite(col = "combined_food_access_location", 
        c("food_access_location_selected" ,"food_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_food_cooling_access_location", 
        c("food_cooling_access_location_selected" ,"food_cooling_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_cooking_access_location", 
        c("cooking_access_location_selected" ,"cooking_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_med_cooling_access_location", 
        c("med_cooling_access_location_selected" ,"med_cooling_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_healthcare_device_access_location", 
        c("healthcare_device_access_location_selected" ,"healthcare_device_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_washing_access_location_location", 
        c("washing_access_location_selected" ,"washing_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_comfort_access_location", 
        c("comfort_access_location_selected" ,"comfort_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_lighting_access_location", 
        c("lighting_access_location_selected" ,"lighting_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_info_access_location", 
        c("info_access_location_selected" ,"info_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_comm_access_location", 
        c("comm_access_location_selected" ,"comm_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_other_task_location", 
        c("other_task_location_selected" ,"other_task_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>%
  unite(col = "combined_primary_reason_facility", 
        c("primary_reason_facility_selected" ,"primary_reason_facility_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) 

data_combined <- data_combined %>%
  unite(col = "combined_relocation_location", 
        c("relocation_location_selected" ,"relocation_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_energy_sources", 
        c("energy_sources_selected" ,"energy_sources_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_backup_energy_system_type", #
        c("backup_energy_system_type_selected" ,"backup_energy_system_type_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_activity_disruption_adaptation", 
        c("activity_disruption_adaptation_selected" ,"activity_disruption_adaptation_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_activity_disruption_health_impact", 
        c("activity_disruption_health_impact_selected" ,"activity_disruption_health_impact_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE)  %>% 
  unite(col = "combined_disrupted_health_impact", 
        c("disrupted_health_impact_selected" ,"disrupted_health_impact_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE)  %>% 
  unite(col = "combined_community_outage_concern", 
        c("community_outage_concern_selected" ,"community_outage_concern_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE)  %>% 
  unite(col = "combined_healthcare_access_location", 
        c("healthcare_access_location_selected" ,"healthcare_access_location_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) 

data_combined <- data_combined %>% 
  unite(col = "combined_gender", 
        c("gender" ,"gender_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_home_ownership", 
        c("home_ownership" ,"home_ownership_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_housing_type", 
        c("housing_type" ,"housing_type_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_languages", 
        c("user_language" ,"languages_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) %>% 
  unite(col = "combined_primary_transport_mode", 
        c("primary_transport_mode_selected" ,"primary_transport_mode_other" ), 
        sep = "; ", # You can change the separator to any character (e.g., comma, empty string)
        na.rm = TRUE) 

data_combined <- data_combined %>% mutate(across(everything(), ~ replace_na(.x, "missing")))


########create age group
data_combined$age_group <- cut(data$age,
                      breaks = c(18, 25, 35, 45, 55, 65, 75, 85, 95, 100),  # Adjust breaks to match labels
                      right = FALSE,                    # Make intervals closed on the left (e.g., [18, 25))
                      labels = c("18-25", "25-35", "35-45", "45-55", "55-65", "65-75", "75-85", "85-95", "95-100"))

save(data_combined, file="D:/01PHD/000NREL_SCORE/04analysis/data/combined_data_choice_1021.Rdata")

```